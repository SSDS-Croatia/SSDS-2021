{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebb3bee9-2168-4bf8-b4ea-ce1d7e31d8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/spark-3.1.2-bin-hadoop3.2/jars/spark-unsafe_2.12-3.1.2.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "21/09/21 07:47:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/09/21 07:47:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "21/09/21 07:47:38 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+---------+------------------+-------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+\n",
      "|           medallion|        hack_license|vendor_id|rate_code|store_and_fwd_flag|    pickup_datetime|   dropoff_datetime|passenger_count|trip_time_in_secs|trip_distance|pickup_longitude|pickup_latitude|dropoff_longitude|dropoff_latitude|\n",
      "+--------------------+--------------------+---------+---------+------------------+-------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+\n",
      "|89D227B655E5C82AE...|BA96DE419E711691B...|      CMT|        1|                 N|2013-01-01 15:11:48|2013-01-01 15:18:10|              4|              382|          1.0|      -73.978165|      40.757977|       -73.989838|       40.751171|\n",
      "|0BD7C8F5BA12B88E0...|9FD8F69F0804BDB55...|      CMT|        1|                 N|2013-01-06 00:18:35|2013-01-06 00:22:54|              1|              259|          1.5|      -74.006683|      40.731781|       -73.994499|        40.75066|\n",
      "|0BD7C8F5BA12B88E0...|9FD8F69F0804BDB55...|      CMT|        1|                 N|2013-01-05 18:49:41|2013-01-05 18:54:23|              1|              282|          1.1|      -74.004707|       40.73777|       -74.009834|       40.726002|\n",
      "|DFD2202EE08F7A8DC...|51EE87E3205C985EF...|      CMT|        1|                 N|2013-01-07 23:54:15|2013-01-07 23:58:20|              2|              244|          0.7|      -73.974602|      40.759945|       -73.984734|       40.759388|\n",
      "|DFD2202EE08F7A8DC...|51EE87E3205C985EF...|      CMT|        1|                 N|2013-01-07 23:25:03|2013-01-07 23:34:24|              1|              560|          2.1|       -73.97625|      40.748528|       -74.002586|       40.747868|\n",
      "+--------------------+--------------------+---------+---------+------------------+-------------------+-------------------+---------------+-----------------+-------------+----------------+---------------+-----------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "session = SparkSession.builder.getOrCreate()\n",
    "context = session.sparkContext\n",
    "df = session.read.csv(\"trip_data_small.csv\", header=True, inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e05324a2-c28e-4934-beeb-47c634806f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+-------------+-----------------+\n",
      "|           medallion|passenger_count|trip_distance|trip_time_in_secs|\n",
      "+--------------------+---------------+-------------+-----------------+\n",
      "|89D227B655E5C82AE...|              4|          1.0|              382|\n",
      "|0BD7C8F5BA12B88E0...|              1|          1.5|              259|\n",
      "|0BD7C8F5BA12B88E0...|              1|          1.1|              282|\n",
      "|DFD2202EE08F7A8DC...|              2|          0.7|              244|\n",
      "|DFD2202EE08F7A8DC...|              1|          2.1|              560|\n",
      "+--------------------+---------------+-------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sel = df.select(\"medallion\", \"passenger_count\", \"trip_distance\", \"trip_time_in_secs\")\n",
    "df_sel.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "605e7c2f-e245-4e1d-ab24-599704183f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.812064833071135"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel.stat.corr('trip_distance', 'trip_time_in_secs', method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ab409fa-533c-493a-8a78-9b04314e25df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.005809447362652621"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sel.stat.corr('trip_distance', 'passenger_count', method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5b5c419-61f9-40e6-9775-353fdb14cdd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+-------------+-----------------+-----------+\n",
      "|           medallion|passenger_count|trip_distance|trip_time_in_secs|   features|\n",
      "+--------------------+---------------+-------------+-----------------+-----------+\n",
      "|89D227B655E5C82AE...|              4|          1.0|              382|[4.0,382.0]|\n",
      "|0BD7C8F5BA12B88E0...|              1|          1.5|              259|[1.0,259.0]|\n",
      "|0BD7C8F5BA12B88E0...|              1|          1.1|              282|[1.0,282.0]|\n",
      "|DFD2202EE08F7A8DC...|              2|          0.7|              244|[2.0,244.0]|\n",
      "|DFD2202EE08F7A8DC...|              1|          2.1|              560|[1.0,560.0]|\n",
      "+--------------------+---------------+-------------+-----------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vectorAssembler = VectorAssembler(inputCols = [\"passenger_count\", \"trip_time_in_secs\"], outputCol = \"features\")\n",
    "df_vec = vectorAssembler.transform(df_sel)\n",
    "df_vec.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b709753-a166-4838-b0f4-039b9956e63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+\n",
      "|   features|trip_distance|\n",
      "+-----------+-------------+\n",
      "|[4.0,382.0]|          1.0|\n",
      "|[1.0,259.0]|          1.5|\n",
      "|[1.0,282.0]|          1.1|\n",
      "|[2.0,244.0]|          0.7|\n",
      "|[1.0,560.0]|          2.1|\n",
      "+-----------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_prep = df_vec.select(['features', 'trip_distance'])\n",
    "df_prep.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27d21eb0-aa6f-46af-8134-3faf7ff34deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = df_prep.randomSplit([0.7, 0.3])\n",
    "df_train = splits[0]\n",
    "df_test = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebf29b06-c97f-4aa5-8cef-5d13ca164065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/09/21 07:51:21 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeSystemBLAS\n",
      "21/09/21 07:51:21 WARN BLAS: Failed to load implementation from: com.github.fommil.netlib.NativeRefBLAS\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.0,0.00519836959257972]\n",
      "Intercept: -0.6666637461506705\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol = 'features', labelCol='trip_distance', maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "lr_model = lr.fit(df_train)\n",
    "print(\"Coefficients: \" + str(lr_model.coefficients))\n",
    "print(\"Intercept: \" + str(lr_model.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9f47e87-65f3-451a-8921-203287355143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 2.021844\n",
      "R2: 0.651278\n",
      "numIterations: 3\n",
      "objectiveHistory: [0.5000000000000001, 0.43358532503359065, 0.23006876770246557, 0.23006876770242157]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 10:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|         residuals|\n",
      "+------------------+\n",
      "|0.5743267617193561|\n",
      "|0.6666637461506705|\n",
      "|0.6666637461506705|\n",
      "|0.6666637461506705|\n",
      "|0.6666637461506705|\n",
      "+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "lr_model_summ = lr_model.summary\n",
    "print(\"RMSE: %f\" % lr_model_summ.rootMeanSquaredError)\n",
    "print(\"R2: %f\" % lr_model_summ.r2)\n",
    "print(\"numIterations: %d\" % lr_model_summ.totalIterations)\n",
    "print(\"objectiveHistory: %s\" % str(lr_model_summ.objectiveHistory))\n",
    "lr_model_summ.residuals.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5f3ac60-e593-4e0f-9f9d-b55607f91812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|     trip_distance|\n",
      "+-------+------------------+\n",
      "|  count|            419072|\n",
      "|   mean|2.8529949268860793|\n",
      "| stddev| 3.423801771231003|\n",
      "|    min|               0.0|\n",
      "|    max|             95.85|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_train.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "054956fa-af3c-46de-87fb-532bcc3433bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data = 2.00746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:=============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on test data = 0.655281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "evaluator_rmse = RegressionEvaluator(labelCol=\"trip_distance\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "evaluator_r2 = RegressionEvaluator(labelCol=\"trip_distance\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "lr_predictions = lr_model.transform(df_test)\n",
    "print(\"RMSE on test data = %g\" % evaluator_rmse.evaluate(lr_predictions))\n",
    "print(\"R2 on test data = %g\" % evaluator_r2.evaluate(lr_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "781f4379-6d73-40e4-9849-a2add5c8b222",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/09/21 07:54:30 WARN BlockManager: Asked to remove block broadcast_39_piece0, which does not exist\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data = 1.93827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:==============>                                           (1 + 3) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on test data = 0.678633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "dt = DecisionTreeRegressor(featuresCol ='features', labelCol = 'trip_distance')\n",
    "dt_model = dt.fit(df_train)\n",
    "dt_predictions = dt_model.transform(df_test)\n",
    "print(\"RMSE on test data = %g\" % evaluator_rmse.evaluate(dt_predictions))\n",
    "print(\"R2 on test data = %g\" % evaluator_r2.evaluate(dt_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7848c31-a955-4e8f-9685-69c0955d43ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test data = 1.92355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 136:============================>                            (2 + 2) / 4]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 on test data = 0.683497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "gbt = GBTRegressor(featuresCol = 'features', labelCol = 'trip_distance', maxIter=10)\n",
    "gbt_model = gbt.fit(df_train)\n",
    "gbt_predictions = gbt_model.transform(df_test)\n",
    "print(\"RMSE on test data = %g\" % evaluator_rmse.evaluate(gbt_predictions))\n",
    "print(\"R2 on test data = %g\" % evaluator_r2.evaluate(gbt_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb8502b-7f9d-4f97-8ff0-615724ca68bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
